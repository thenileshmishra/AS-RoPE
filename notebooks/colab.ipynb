{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a24572ca",
   "metadata": {},
   "source": [
    "# Colab A100 Runbook (Minimal)\n",
    "\n",
    "Run cells in order.\n",
    "\n",
    "This notebook does only what is required: pull latest code, run experiments, aggregate results, and export figures/tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390e906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Pull latest repo + setup environment\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_URL = \"https://github.com/thenileshmishra/AS-RoPE.git\"  # change if needed\n",
    "ROOT = Path('/content/Neur')\n",
    "\n",
    "if ROOT.exists() and (ROOT / '.git').exists():\n",
    "    subprocess.run(['git', '-C', str(ROOT), 'fetch', 'origin'], check=True)\n",
    "    subprocess.run(['git', '-C', str(ROOT), 'reset', '--hard', 'origin/main'], check=True)\n",
    "else:\n",
    "    if ROOT.exists():\n",
    "        subprocess.run(['rm', '-rf', str(ROOT)], check=True)\n",
    "    subprocess.run(['git', 'clone', REPO_URL, str(ROOT)], check=True)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', str(ROOT / 'requirements.txt')], check=True)\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', 'pandas', 'matplotlib', 'seaborn', 'tabulate'], check=True)\n",
    "\n",
    "print('ROOT =', ROOT)\n",
    "print('Python =', sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea8a701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding rope --seed 42 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1817.1959 | lr 6.000000e-05 | tokens 131072 | 1.9s\n",
      "Seed 42 outputs saved to: /content/Neur/results/train_runs/rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/rope/seed_42/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/rope/seed_42.json\n",
      "context=1024 ppl=1046980011068904544665600.000000\n",
      "context=2048 ppl=1047589949362029146931200.000000\n",
      "context=4096 ppl=1051276286187080177942528.000000\n",
      "context=8192 ppl=1055717955001199353659392.000000\n",
      "results_json=/content/Neur/results/rope/seed_42.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding rope --seed 123 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=rope\n",
      "seeds=[123]\n",
      "\n",
      "--- Seed run start | positional_encoding=rope | seed=123 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1818.2674 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 123 outputs saved to: /content/Neur/results/train_runs/rope/seed_123\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/rope/seed_123/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 123 --device cuda --results_json /content/Neur/results/rope/seed_123.json\n",
      "context=1024 ppl=533120456462885946654720.000000\n",
      "context=2048 ppl=532254848949074438127616.000000\n",
      "context=4096 ppl=532813324505599384223744.000000\n",
      "context=8192 ppl=533683095672624752099328.000000\n",
      "results_json=/content/Neur/results/rope/seed_123.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding rope --seed 999 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=rope\n",
      "seeds=[999]\n",
      "\n",
      "--- Seed run start | positional_encoding=rope | seed=999 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1813.9161 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 999 outputs saved to: /content/Neur/results/train_runs/rope/seed_999\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/rope/seed_999/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 999 --device cuda --results_json /content/Neur/results/rope/seed_999.json\n",
      "context=1024 ppl=902376998369733728272384.000000\n",
      "context=2048 ppl=903803823418593834434560.000000\n",
      "context=4096 ppl=907246786163369475833856.000000\n",
      "context=8192 ppl=911130373062097822023680.000000\n",
      "results_json=/content/Neur/results/rope/seed_999.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding scaled_rope --seed 42 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=scaled_rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=scaled_rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1817.1953 | lr 6.000000e-05 | tokens 131072 | 2.0s\n",
      "Seed 42 outputs saved to: /content/Neur/results/train_runs/scaled_rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/scaled_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/scaled_rope/seed_42/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/scaled_rope/seed_42.json\n",
      "context=1024 ppl=1047027992586222349320192.000000\n",
      "context=2048 ppl=1047641662042822785630208.000000\n",
      "context=4096 ppl=1051325220998401799225344.000000\n",
      "context=8192 ppl=1055775551256253513596928.000000\n",
      "results_json=/content/Neur/results/scaled_rope/seed_42.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding scaled_rope --seed 123 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "context=1024 ppl=533116745882346570383360.000000\n",
      "context=2048 ppl=532249970595563571249152.000000\n",
      "context=4096 ppl=532807191005067443437568.000000\n",
      "context=8192 ppl=533677319432932738203648.000000\n",
      "results_json=/content/Neur/results/scaled_rope/seed_123.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding scaled_rope --seed 999 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=scaled_rope\n",
      "seeds=[999]\n",
      "\n",
      "--- Seed run start | positional_encoding=scaled_rope | seed=999 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1813.9173 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 999 outputs saved to: /content/Neur/results/train_runs/scaled_rope/seed_999\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/scaled_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/scaled_rope/seed_999/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 999 --device cuda --results_json /content/Neur/results/scaled_rope/seed_999.json\n",
      "context=1024 ppl=902086482957002178822144.000000\n",
      "context=2048 ppl=903506277461801513779200.000000\n",
      "context=4096 ppl=906951567966085744427008.000000\n",
      "context=8192 ppl=910833891145238882287616.000000\n",
      "results_json=/content/Neur/results/scaled_rope/seed_999.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding as_rope --seed 42 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=as_rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=as_rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "as_rope_per_layer_gates=False allow_negative_gates=False\n",
      "step     1 | train_loss 1817.2002 | lr 6.000000e-05 | tokens 131072 | 1.7s\n",
      "Seed 42 outputs saved to: /content/Neur/results/train_runs/as_rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/as_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/as_rope/seed_42/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/as_rope/seed_42.json\n",
      "context=1024 ppl=1029335171495279697330176.000000\n",
      "context=2048 ppl=1029877951247700694401024.000000\n",
      "context=4096 ppl=1033215691172476685910016.000000\n",
      "context=8192 ppl=1037497187696621612171264.000000\n",
      "results_json=/content/Neur/results/as_rope/seed_42.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding as_rope --seed 123 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=as_rope\n",
      "seeds=[123]\n",
      "\n",
      "--- Seed run start | positional_encoding=as_rope | seed=123 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "as_rope_per_layer_gates=False allow_negative_gates=False\n",
      "step     1 | train_loss 1818.2839 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 123 outputs saved to: /content/Neur/results/train_runs/as_rope/seed_123\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/as_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/as_rope/seed_123/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 123 --device cuda --results_json /content/Neur/results/as_rope/seed_123.json\n",
      "context=1024 ppl=534166033340363706466304.000000\n",
      "context=2048 ppl=533318697370931062374400.000000\n",
      "context=4096 ppl=533716719303163012710400.000000\n",
      "context=8192 ppl=534578031973626311344128.000000\n",
      "results_json=/content/Neur/results/as_rope/seed_123.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding as_rope --seed 999 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=as_rope\n",
      "seeds=[999]\n",
      "\n",
      "--- Seed run start | positional_encoding=as_rope | seed=999 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "as_rope_per_layer_gates=False allow_negative_gates=False\n",
      "step     1 | train_loss 1813.9450 | lr 6.000000e-05 | tokens 131072 | 1.7s\n",
      "Seed 999 outputs saved to: /content/Neur/results/train_runs/as_rope/seed_999\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/as_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/as_rope/seed_999/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 999 --device cuda --results_json /content/Neur/results/as_rope/seed_999.json\n",
      "context=1024 ppl=916186818475696125378560.000000\n",
      "context=2048 ppl=917613692536793902088192.000000\n",
      "context=4096 ppl=920786663382632896659456.000000\n",
      "context=8192 ppl=924856422446613665939456.000000\n",
      "results_json=/content/Neur/results/as_rope/seed_999.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding alibi --seed 42 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=alibi\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=alibi | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1788.9197 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 42 outputs saved to: /content/Neur/results/train_runs/alibi/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/alibi/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/alibi/seed_42/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/alibi/seed_42.json\n",
      "context=1024 ppl=494795543428679119929344.000000\n",
      "context=2048 ppl=494246628109360776085504.000000\n",
      "context=4096 ppl=494002407959633483268096.000000\n",
      "context=8192 ppl=493904815492630010920960.000000\n",
      "results_json=/content/Neur/results/alibi/seed_42.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding alibi --seed 123 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=alibi\n",
      "seeds=[123]\n",
      "\n",
      "--- Seed run start | positional_encoding=alibi | seed=123 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1789.8608 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 123 outputs saved to: /content/Neur/results/train_runs/alibi/seed_123\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/alibi/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/alibi/seed_123/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 123 --device cuda --results_json /content/Neur/results/alibi/seed_123.json\n",
      "context=1024 ppl=373378064601200824680448.000000\n",
      "context=2048 ppl=373087501594819372777472.000000\n",
      "context=4096 ppl=372965118860945589796864.000000\n",
      "context=8192 ppl=372892324383626476126208.000000\n",
      "results_json=/content/Neur/results/alibi/seed_123.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding alibi --seed 999 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=alibi\n",
      "seeds=[999]\n",
      "\n",
      "--- Seed run start | positional_encoding=alibi | seed=999 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1786.2291 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 999 outputs saved to: /content/Neur/results/train_runs/alibi/seed_999\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/alibi/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/alibi/seed_999/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 999 --device cuda --results_json /content/Neur/results/alibi/seed_999.json\n",
      "context=1024 ppl=655303892301244201435136.000000\n",
      "context=2048 ppl=654682762413856673234944.000000\n",
      "context=4096 ppl=654356216658170531020800.000000\n",
      "context=8192 ppl=654203001682103522820096.000000\n",
      "results_json=/content/Neur/results/alibi/seed_999.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding ntk_scaled_rope --seed 42 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=ntk_scaled_rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=ntk_scaled_rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1817.1959 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 42 outputs saved to: /content/Neur/results/train_runs/ntk_scaled_rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/ntk_scaled_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/ntk_scaled_rope/seed_42/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/ntk_scaled_rope/seed_42.json\n",
      "context=1024 ppl=1046478007377394348851200.000000\n",
      "context=2048 ppl=1043615369692456752775168.000000\n",
      "context=4096 ppl=1043408350010569568288768.000000\n",
      "context=8192 ppl=1045225857424195019866112.000000\n",
      "results_json=/content/Neur/results/ntk_scaled_rope/seed_42.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding ntk_scaled_rope --seed 123 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=ntk_scaled_rope\n",
      "seeds=[123]\n",
      "\n",
      "--- Seed run start | positional_encoding=ntk_scaled_rope | seed=123 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1818.2674 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 123 outputs saved to: /content/Neur/results/train_runs/ntk_scaled_rope/seed_123\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/ntk_scaled_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/ntk_scaled_rope/seed_123/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 123 --device cuda --results_json /content/Neur/results/ntk_scaled_rope/seed_123.json\n",
      "context=1024 ppl=534147352410529397211136.000000\n",
      "context=2048 ppl=532182760426944061243392.000000\n",
      "context=4096 ppl=531335063442998117269504.000000\n",
      "context=8192 ppl=531276261688573517889536.000000\n",
      "results_json=/content/Neur/results/ntk_scaled_rope/seed_123.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding ntk_scaled_rope --seed 999 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 0.0003 --weight_decay 0.1 --max_steps 20 --warmup_steps 5 --eval_interval 20 --grad_clip 1.0 --grad_accum_steps 4 --output_dir results/train_runs --device cuda --fp16\n",
      "positional_encoding=ntk_scaled_rope\n",
      "seeds=[999]\n",
      "\n",
      "--- Seed run start | positional_encoding=ntk_scaled_rope | seed=999 ---\n",
      "Training on cuda\n",
      "Parameters: 44.63M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "step     1 | train_loss 1813.9161 | lr 6.000000e-05 | tokens 131072 | 1.6s\n",
      "Seed 999 outputs saved to: /content/Neur/results/train_runs/ntk_scaled_rope/seed_999\n",
      "All-seed metrics saved: /content/Neur/results/train_runs/ntk_scaled_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/train_runs/ntk_scaled_rope/seed_999/checkpoint.pt --context_lengths 1024,2048,4096,8192 --seed 999 --device cuda --results_json /content/Neur/results/ntk_scaled_rope/seed_999.json\n",
      "context=1024 ppl=899376182778554025508864.000000\n",
      "context=2048 ppl=898154386009548069535744.000000\n",
      "context=4096 ppl=898845692404962217164800.000000\n",
      "context=8192 ppl=901195143815755265474560.000000\n",
      "results_json=/content/Neur/results/ntk_scaled_rope/seed_999.json\n",
      "\n",
      "Phase 1 complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: PHASE 1 — Full baseline suite (5 methods x 3 seeds), then eval at 1024/2048/4096/8192\n",
    "import json\n",
    "import shlex\n",
    "\n",
    "# Set to False for full paper-scale run. True is for error-free end-to-end debug run.\n",
    "DEBUG_QUICK = True\n",
    "\n",
    "METHODS = ['rope', 'scaled_rope', 'as_rope', 'alibi', 'ntk_scaled_rope']\n",
    "SEEDS = [42, 123, 999]\n",
    "\n",
    "TRAIN_CFG = {\n",
    "    'layers': 6,\n",
    "    'n_heads': 8,\n",
    "    'd_model': 512,\n",
    "    'context_length': 1024,\n",
    "    'batch_size': 32,\n",
    "    'optimizer': 'adamw',\n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 0.1,\n",
    "    'max_steps': 60000 if not DEBUG_QUICK else 20,\n",
    "    'warmup_steps': 3000 if not DEBUG_QUICK else 5,\n",
    "    'eval_interval': 5000 if not DEBUG_QUICK else 20,\n",
    "    'grad_clip': 1.0,\n",
    "    'fp16': True,\n",
    "    'grad_accum_steps': 4,\n",
    "}\n",
    "\n",
    "EVAL_LENGTHS = '1024,2048,4096,8192'\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    print('\\n$', ' '.join(shlex.quote(c) for c in cmd))\n",
    "    proc = subprocess.run(cmd, cwd=ROOT, text=True, capture_output=True)\n",
    "    if proc.stdout:\n",
    "        print(proc.stdout)\n",
    "    if proc.returncode != 0:\n",
    "        if proc.stderr:\n",
    "            print(proc.stderr)\n",
    "        raise RuntimeError(f'Command failed with exit code {proc.returncode}')\n",
    "\n",
    "for method in METHODS:\n",
    "    for seed in SEEDS:\n",
    "        run_dir = ROOT / 'results' / 'train_runs' / method / f'seed_{seed}'\n",
    "        out_json = ROOT / 'results' / method / f'seed_{seed}.json'\n",
    "        out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        train_cmd = [\n",
    "            sys.executable, '-m', 'src.train',\n",
    "            '--positional_encoding', method,\n",
    "            '--seed', str(seed),\n",
    "            '--layers', str(TRAIN_CFG['layers']),\n",
    "            '--n_heads', str(TRAIN_CFG['n_heads']),\n",
    "            '--d_model', str(TRAIN_CFG['d_model']),\n",
    "            '--context_length', str(TRAIN_CFG['context_length']),\n",
    "            '--batch_size', str(TRAIN_CFG['batch_size']),\n",
    "            '--optimizer', TRAIN_CFG['optimizer'],\n",
    "            '--lr', str(TRAIN_CFG['lr']),\n",
    "            '--weight_decay', str(TRAIN_CFG['weight_decay']),\n",
    "            '--max_steps', str(TRAIN_CFG['max_steps']),\n",
    "            '--warmup_steps', str(TRAIN_CFG['warmup_steps']),\n",
    "            '--eval_interval', str(TRAIN_CFG['eval_interval']),\n",
    "            '--grad_clip', str(TRAIN_CFG['grad_clip']),\n",
    "            '--grad_accum_steps', str(TRAIN_CFG['grad_accum_steps']),\n",
    "            '--output_dir', 'results/train_runs',\n",
    "            '--device', 'cuda',\n",
    "        ]\n",
    "        if TRAIN_CFG['fp16']:\n",
    "            train_cmd.append('--fp16')\n",
    "\n",
    "        run_cmd(train_cmd)\n",
    "\n",
    "        ckpt = run_dir / 'checkpoint.pt'\n",
    "        eval_cmd = [\n",
    "            sys.executable, '-m', 'src.eval_perplexity',\n",
    "            '--checkpoint_path', str(ckpt),\n",
    "            '--context_lengths', EVAL_LENGTHS,\n",
    "            '--seed', str(seed),\n",
    "            '--device', 'cuda',\n",
    "            '--results_json', str(out_json),\n",
    "        ]\n",
    "        run_cmd(eval_cmd)\n",
    "\n",
    "print('Phase 1 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7875782a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /content/Neur/results/summary.csv\n",
      "Saved: /content/Neur/results/summary.tex\n",
      "Saved: /content/Neur/figures/ppl_vs_length.pdf\n",
      "Saved: /content/Neur/figures/ppl_vs_length_with_errorbars.pdf\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "method",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "mean_ppl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "std_ppl",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rope_mean",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "rel_improve_vs_rope_pct",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "26a22206-6722-4198-9c4e-8ceac18be9e6",
       "rows": [
        [
         "0",
         "alibi",
         "1024",
         "5.07825833443708e+23",
         "1.4141387635057411e+23",
         "8.274924886338412e+23",
         "38.63076216170745"
        ],
        [
         "1",
         "as_rope",
         "1024",
         "8.265626744371132e+23",
         "2.5946576699298324e+23",
         "8.274924886338412e+23",
         "0.11236527334080028"
        ],
        [
         "2",
         "ntk_scaled_rope",
         "1024",
         "8.266671808554924e+23",
         "2.6379087214151295e+23",
         "8.274924886338412e+23",
         "0.09973598427598634"
        ],
        [
         "3",
         "rope",
         "1024",
         "8.274924886338412e+23",
         "2.6498807107823303e+23",
         "8.274924886338412e+23",
         "0.0"
        ],
        [
         "4",
         "scaled_rope",
         "1024",
         "8.27410407141857e+23",
         "2.6496901629538676e+23",
         "8.274924886338412e+23",
         "0.009919303572133708"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "\n",
       "  <div id=\"df-3920d62d-4df3-4720-9acd-557d7edf472b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>length</th>\n",
       "      <th>mean_ppl</th>\n",
       "      <th>std_ppl</th>\n",
       "      <th>rope_mean</th>\n",
       "      <th>rel_improve_vs_rope_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alibi</td>\n",
       "      <td>1024</td>\n",
       "      <td>5.078258e+23</td>\n",
       "      <td>1.414139e+23</td>\n",
       "      <td>8.274925e+23</td>\n",
       "      <td>38.630762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>as_rope</td>\n",
       "      <td>1024</td>\n",
       "      <td>8.265627e+23</td>\n",
       "      <td>2.594658e+23</td>\n",
       "      <td>8.274925e+23</td>\n",
       "      <td>0.112365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ntk_scaled_rope</td>\n",
       "      <td>1024</td>\n",
       "      <td>8.266672e+23</td>\n",
       "      <td>2.637909e+23</td>\n",
       "      <td>8.274925e+23</td>\n",
       "      <td>0.099736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rope</td>\n",
       "      <td>1024</td>\n",
       "      <td>8.274925e+23</td>\n",
       "      <td>2.649881e+23</td>\n",
       "      <td>8.274925e+23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scaled_rope</td>\n",
       "      <td>1024</td>\n",
       "      <td>8.274104e+23</td>\n",
       "      <td>2.649690e+23</td>\n",
       "      <td>8.274925e+23</td>\n",
       "      <td>0.009919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3920d62d-4df3-4720-9acd-557d7edf472b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-3920d62d-4df3-4720-9acd-557d7edf472b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-3920d62d-4df3-4720-9acd-557d7edf472b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "            method  length      mean_ppl       std_ppl     rope_mean  \\\n",
       "0            alibi    1024  5.078258e+23  1.414139e+23  8.274925e+23   \n",
       "1          as_rope    1024  8.265627e+23  2.594658e+23  8.274925e+23   \n",
       "2  ntk_scaled_rope    1024  8.266672e+23  2.637909e+23  8.274925e+23   \n",
       "3             rope    1024  8.274925e+23  2.649881e+23  8.274925e+23   \n",
       "4      scaled_rope    1024  8.274104e+23  2.649690e+23  8.274925e+23   \n",
       "\n",
       "   rel_improve_vs_rope_pct  \n",
       "0                38.630762  \n",
       "1                 0.112365  \n",
       "2                 0.099736  \n",
       "3                 0.000000  \n",
       "4                 0.009919  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4: PHASE 2 — Statistical aggregation + LaTeX + plots (in notebook)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context('talk')\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "rows = []\n",
    "for method in METHODS:\n",
    "    for seed in SEEDS:\n",
    "        p = ROOT / 'results' / method / f'seed_{seed}.json'\n",
    "        if not p.exists():\n",
    "            continue\n",
    "        with p.open() as f:\n",
    "            obj = json.load(f)\n",
    "        for length_str, ppl in obj['perplexity'].items():\n",
    "            rows.append({'method': method, 'seed': seed, 'length': int(length_str), 'ppl': float(ppl)})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "assert len(df) > 0, 'No result JSON files found. Run Phase 1 first.'\n",
    "\n",
    "summary = (\n",
    "    df.groupby(['method', 'length'], as_index=False)\n",
    "      .agg(mean_ppl=('ppl', 'mean'), std_ppl=('ppl', 'std'))\n",
    "      .fillna(0.0)\n",
    ")\n",
    "\n",
    "rope_ref = summary[summary['method'] == 'rope'][['length', 'mean_ppl']].rename(columns={'mean_ppl': 'rope_mean'})\n",
    "summary = summary.merge(rope_ref, on='length', how='left')\n",
    "summary['rel_improve_vs_rope_pct'] = 100.0 * (summary['rope_mean'] - summary['mean_ppl']) / summary['rope_mean']\n",
    "summary = summary.sort_values(['length', 'method']).reset_index(drop=True)\n",
    "\n",
    "results_dir = ROOT / 'results'\n",
    "fig_dir = ROOT / 'figures'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary_csv = results_dir / 'summary.csv'\n",
    "summary_tex = results_dir / 'summary.tex'\n",
    "summary.to_csv(summary_csv, index=False)\n",
    "\n",
    "pivot = summary.pivot(index='method', columns='length', values='mean_ppl')\n",
    "pivot = pivot[[c for c in sorted(pivot.columns)]]\n",
    "with summary_tex.open('w', encoding='utf-8') as f:\n",
    "    f.write(pivot.to_latex(float_format=lambda x: f'{x:.4f}', caption='Perplexity across context lengths', label='tab:ppl_summary'))\n",
    "\n",
    "# Plot 1: means\n",
    "plt.figure(figsize=(8, 5))\n",
    "for method in METHODS:\n",
    "    sub = summary[summary['method'] == method].sort_values('length')\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    plt.plot(sub['length'], sub['mean_ppl'], marker='o', label=method)\n",
    "plt.xscale('log', base=2)\n",
    "plt.xlabel('Context length')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity vs Context Length')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / 'ppl_vs_length.pdf')\n",
    "plt.close()\n",
    "\n",
    "# Plot 2: means + std error bars\n",
    "plt.figure(figsize=(8, 5))\n",
    "for method in METHODS:\n",
    "    sub = summary[summary['method'] == method].sort_values('length')\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    plt.errorbar(sub['length'], sub['mean_ppl'], yerr=sub['std_ppl'], marker='o', capsize=4, label=method)\n",
    "plt.xscale('log', base=2)\n",
    "plt.xlabel('Context length')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity vs Context Length (Mean ± Std)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(fig_dir / 'ppl_vs_length_with_errorbars.pdf')\n",
    "plt.close()\n",
    "\n",
    "print('Saved:', summary_csv)\n",
    "print('Saved:', summary_tex)\n",
    "print('Saved:', fig_dir / 'ppl_vs_length.pdf')\n",
    "print('Saved:', fig_dir / 'ppl_vs_length_with_errorbars.pdf')\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6748e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding rope --seed 42 --layers 8 --n_heads 8 --d_model 768 --context_length 1024 --batch_size 8 --grad_accum_steps 16 --optimizer adamw --lr 3e-4 --weight_decay 0.1 --max_steps 10 --warmup_steps 3 --eval_interval 10 --grad_clip 1.0 --fp16 --output_dir results/scaling --device cuda\n",
      "positional_encoding=rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 95.28M\n",
      "d_model=768 n_layers=8 n_heads=8 context_length=1024 batch_size=8 grad_accum_steps=16 fp16=True\n",
      "step     1 | train_loss 10502.0366 | lr 1.000000e-04 | tokens 131072 | 2.2s\n",
      "Seed 42 outputs saved to: /content/Neur/results/scaling/rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/scaling/rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/scaling/rope/seed_42/checkpoint.pt --context_lengths 1024,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/scaling/rope_seed_42.json\n",
      "context=1024 ppl=585619752065314817138131034177536.000000\n",
      "context=4096 ppl=580499205756503861525572285890560.000000\n",
      "context=8192 ppl=580291940714793154845458097504256.000000\n",
      "results_json=/content/Neur/results/scaling/rope_seed_42.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding as_rope --seed 42 --layers 8 --n_heads 8 --d_model 768 --context_length 1024 --batch_size 8 --grad_accum_steps 16 --optimizer adamw --lr 3e-4 --weight_decay 0.1 --max_steps 10 --warmup_steps 3 --eval_interval 10 --grad_clip 1.0 --fp16 --output_dir results/scaling --device cuda\n",
      "positional_encoding=as_rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=as_rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 95.28M\n",
      "d_model=768 n_layers=8 n_heads=8 context_length=1024 batch_size=8 grad_accum_steps=16 fp16=True\n",
      "as_rope_per_layer_gates=False allow_negative_gates=False\n",
      "step     1 | train_loss 10502.1642 | lr 1.000000e-04 | tokens 131072 | 2.3s\n",
      "Seed 42 outputs saved to: /content/Neur/results/scaling/as_rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/scaling/as_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/scaling/as_rope/seed_42/checkpoint.pt --context_lengths 1024,4096,8192 --seed 42 --device cuda --results_json /content/Neur/results/scaling/as_rope_seed_42.json\n",
      "context=1024 ppl=574125684998859520137068655149056.000000\n",
      "context=4096 ppl=569008945654692111721522391941120.000000\n",
      "context=8192 ppl=568773614122444946801037217366016.000000\n",
      "results_json=/content/Neur/results/scaling/as_rope_seed_42.json\n",
      "\n",
      "Phase 3 complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: PHASE 3 — Scaling check (single seed=42; rope vs as_rope)\n",
    "SCALING_METHODS = ['rope', 'as_rope']\n",
    "SCALING_SEED = 42\n",
    "\n",
    "for method in SCALING_METHODS:\n",
    "    run_dir = ROOT / 'results' / 'scaling' / method / f'seed_{SCALING_SEED}'\n",
    "    out_json = ROOT / 'results' / 'scaling' / f'{method}_seed_{SCALING_SEED}.json'\n",
    "    out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_cmd = [\n",
    "        sys.executable, '-m', 'src.train',\n",
    "        '--positional_encoding', method,\n",
    "        '--seed', str(SCALING_SEED),\n",
    "        '--layers', '8',\n",
    "        '--n_heads', '8',\n",
    "        '--d_model', '768',\n",
    "        '--context_length', '1024',\n",
    "        '--batch_size', '8',\n",
    "        '--grad_accum_steps', '16',\n",
    "        '--optimizer', 'adamw',\n",
    "        '--lr', '3e-4',\n",
    "        '--weight_decay', '0.1',\n",
    "        '--max_steps', '40000' if not DEBUG_QUICK else '10',\n",
    "        '--warmup_steps', '2000' if not DEBUG_QUICK else '3',\n",
    "        '--eval_interval', '5000' if not DEBUG_QUICK else '10',\n",
    "        '--grad_clip', '1.0',\n",
    "        '--fp16',\n",
    "        '--output_dir', 'results/scaling',\n",
    "        '--device', 'cuda',\n",
    "    ]\n",
    "    run_cmd(train_cmd)\n",
    "\n",
    "    ckpt = run_dir / 'checkpoint.pt'\n",
    "    eval_cmd = [\n",
    "        sys.executable, '-m', 'src.eval_perplexity',\n",
    "        '--checkpoint_path', str(ckpt),\n",
    "        '--context_lengths', '1024,4096,8192',\n",
    "        '--seed', str(SCALING_SEED),\n",
    "        '--device', 'cuda',\n",
    "        '--results_json', str(out_json),\n",
    "    ]\n",
    "    run_cmd(eval_cmd)\n",
    "\n",
    "print('Phase 3 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "348d7c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ /usr/bin/python3 -m src.train --positional_encoding as_rope --seed 42 --layers 6 --n_heads 8 --d_model 512 --context_length 1024 --batch_size 32 --optimizer adamw --lr 3e-4 --weight_decay 0.1 --max_steps 10 --warmup_steps 3 --eval_interval 10 --grad_clip 1.0 --grad_accum_steps 4 --fp16 --output_dir results/ablations/as_rope_per_layer_gates --device cuda --as_rope_per_layer_gates\n",
      "positional_encoding=as_rope\n",
      "seeds=[42]\n",
      "\n",
      "--- Seed run start | positional_encoding=as_rope | seed=42 ---\n",
      "Training on cuda\n",
      "Parameters: 44.64M\n",
      "d_model=512 n_layers=6 n_heads=8 context_length=1024 batch_size=32 grad_accum_steps=4 fp16=True\n",
      "as_rope_per_layer_gates=True allow_negative_gates=False\n",
      "step     1 | train_loss 1817.2002 | lr 1.000000e-04 | tokens 131072 | 1.6s\n",
      "Seed 42 outputs saved to: /content/Neur/results/ablations/as_rope_per_layer_gates/as_rope/seed_42\n",
      "All-seed metrics saved: /content/Neur/results/ablations/as_rope_per_layer_gates/as_rope/all_seeds_metrics.json\n",
      "\n",
      "\n",
      "$ /usr/bin/python3 -m src.eval_perplexity --checkpoint_path /content/Neur/results/ablations/as_rope_per_layer_gates/as_rope/seed_42/checkpoint.pt --context_lengths 1024,4096 --seed 42 --device cuda --results_json /content/Neur/results/ablations/as_rope_per_layer_gates.json\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/content/Neur/src/eval_perplexity.py\", line 200, in <module>\n",
      "    main()\n",
      "  File \"/content/Neur/src/eval_perplexity.py\", line 169, in main\n",
      "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\", line 2635, in load_state_dict\n",
      "    raise RuntimeError(\n",
      "RuntimeError: Error(s) in loading state_dict for GPT:\n",
      "\tsize mismatch for freq_gates: copying a param with shape torch.Size([6, 256]) from checkpoint, the shape in current model is torch.Size([256]).\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Command failed with exit code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4179/3462874393.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;34m'--results_json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     ]\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mrun_cmd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_cmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Phase 4 complete.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-4179/2964584825.py\u001b[0m in \u001b[0;36mrun_cmd\u001b[0;34m(cmd)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Command failed with exit code {proc.returncode}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mMETHODS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Command failed with exit code 1"
     ]
    }
   ],
   "source": [
    "# Cell 5: PHASE 4 — AS-RoPE ablations (20k steps)\n",
    "ABLATIONS = [\n",
    "    {\n",
    "        'name': 'as_rope_per_layer_gates',\n",
    "        'extra_train_args': ['--as_rope_per_layer_gates'],\n",
    "    },\n",
    "    {\n",
    "        'name': 'as_rope_without_positivity',\n",
    "        'extra_train_args': ['--allow_negative_gates'],\n",
    "    },\n",
    "    {\n",
    "        'name': 'as_rope_gate_weight_decay',\n",
    "        'extra_train_args': ['--gate_weight_decay', '0.1'],\n",
    "    },\n",
    "]\n",
    "\n",
    "for ab in ABLATIONS:\n",
    "    run_dir = ROOT / 'results' / 'ablations' / ab['name'] / 'as_rope' / 'seed_42'\n",
    "    out_json = ROOT / 'results' / 'ablations' / f\"{ab['name']}.json\"\n",
    "    out_json.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_cmd = [\n",
    "        sys.executable, '-m', 'src.train',\n",
    "        '--positional_encoding', 'as_rope',\n",
    "        '--seed', '42',\n",
    "        '--layers', '6',\n",
    "        '--n_heads', '8',\n",
    "        '--d_model', '512',\n",
    "        '--context_length', '1024',\n",
    "        '--batch_size', '32',\n",
    "        '--optimizer', 'adamw',\n",
    "        '--lr', '3e-4',\n",
    "        '--weight_decay', '0.1',\n",
    "        '--max_steps', '20000' if not DEBUG_QUICK else '10',\n",
    "        '--warmup_steps', '1000' if not DEBUG_QUICK else '3',\n",
    "        '--eval_interval', '5000' if not DEBUG_QUICK else '10',\n",
    "        '--grad_clip', '1.0',\n",
    "        '--grad_accum_steps', '4',\n",
    "        '--fp16',\n",
    "        '--output_dir', f\"results/ablations/{ab['name']}\",\n",
    "        '--device', 'cuda',\n",
    "    ] + ab['extra_train_args']\n",
    "\n",
    "    run_cmd(train_cmd)\n",
    "\n",
    "    ckpt = run_dir / 'checkpoint.pt'\n",
    "    eval_cmd = [\n",
    "        sys.executable, '-m', 'src.eval_perplexity',\n",
    "        '--checkpoint_path', str(ckpt),\n",
    "        '--context_lengths', '1024,4096',\n",
    "        '--seed', '42',\n",
    "        '--device', 'cuda',\n",
    "        '--results_json', str(out_json),\n",
    "    ]\n",
    "    run_cmd(eval_cmd)\n",
    "\n",
    "print('Phase 4 complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96ff2b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /content/Neur/figures/spectral_profile.pdf\n",
      "Saved: /content/Neur/figures/effective_period.pdf\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: PHASE 5 — Spectral analysis plots for final AS-RoPE checkpoint (seed=42 main run)\n",
    "import math\n",
    "import torch\n",
    "\n",
    "ckpt_path = ROOT / 'results' / 'train_runs' / 'as_rope' / 'seed_42' / 'checkpoint.pt'\n",
    "assert ckpt_path.exists(), f'Checkpoint not found: {ckpt_path}'\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "state = ckpt['model_state_dict']\n",
    "config = ckpt.get('config', {})\n",
    "\n",
    "gate_key = 'freq_gates'\n",
    "assert gate_key in state, 'freq_gates not found in checkpoint; ensure AS-RoPE run completed.'\n",
    "gates = state[gate_key].float().cpu()\n",
    "\n",
    "if gates.ndim == 2:  # per-layer gates -> take mean profile\n",
    "    gates_plot = gates.mean(dim=0)\n",
    "else:\n",
    "    gates_plot = gates\n",
    "\n",
    "d_model = int(config.get('d_model', 512))\n",
    "half_dim = d_model // 2\n",
    "idx = torch.arange(half_dim, dtype=torch.float32)\n",
    "omega = 1.0 / (10000.0 ** (2.0 * idx / d_model))\n",
    "\n",
    "g = gates_plot[:half_dim]\n",
    "effective = g * omega\n",
    "period = (2.0 * math.pi) / (effective.abs() + 1e-12)\n",
    "\n",
    "fig_dir = ROOT / 'figures'\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# spectral_profile.pdf (3-panel)\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 4.5))\n",
    "ax[0].plot(g.numpy())\n",
    "ax[0].set_title('Gate vs Frequency Index')\n",
    "ax[0].set_xlabel('Index i')\n",
    "ax[0].set_ylabel('g_i')\n",
    "\n",
    "ax[1].plot(omega.numpy(), label='original $\\\\omega_i$')\n",
    "ax[1].plot(effective.numpy(), label='effective $g_i\\\\omega_i$')\n",
    "ax[1].set_yscale('log')\n",
    "ax[1].set_title('Original vs Effective Frequency')\n",
    "ax[1].set_xlabel('Index i')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].hist(g.numpy(), bins=40)\n",
    "ax[2].set_title('Histogram of Gates')\n",
    "ax[2].set_xlabel('g_i')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / 'spectral_profile.pdf')\n",
    "plt.close(fig)\n",
    "\n",
    "# effective_period.pdf\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 4.5))\n",
    "ax.hist(period.numpy(), bins=50)\n",
    "ax.set_title('Histogram of Effective Periods')\n",
    "ax.set_xlabel('T_i = 2π / |g_iω_i|')\n",
    "ax.set_ylabel('Count')\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / 'effective_period.pdf')\n",
    "plt.close(fig)\n",
    "\n",
    "print('Saved:', fig_dir / 'spectral_profile.pdf')\n",
    "print('Saved:', fig_dir / 'effective_period.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84f2a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK   /content/Neur/results/summary.csv\n",
      "OK   /content/Neur/results/summary.tex\n",
      "OK   /content/Neur/figures/ppl_vs_length.pdf\n",
      "OK   /content/Neur/figures/ppl_vs_length_with_errorbars.pdf\n",
      "OK   /content/Neur/figures/spectral_profile.pdf\n",
      "OK   /content/Neur/figures/effective_period.pdf\n",
      "\n",
      "Sample result files:\n",
      "- /content/Neur/results/ablations/as_rope_per_layer_gates/as_rope/all_seeds_metrics.json\n",
      "- /content/Neur/results/ablations/as_rope_per_layer_gates/as_rope/seed_42/metrics.json\n",
      "- /content/Neur/results/alibi/seed_123.json\n",
      "- /content/Neur/results/alibi/seed_42.json\n",
      "- /content/Neur/results/alibi/seed_999.json\n",
      "- /content/Neur/results/as_rope/seed_123.json\n",
      "- /content/Neur/results/as_rope/seed_42.json\n",
      "- /content/Neur/results/as_rope/seed_999.json\n",
      "- /content/Neur/results/ntk_scaled_rope/seed_123.json\n",
      "- /content/Neur/results/ntk_scaled_rope/seed_42.json\n",
      "- /content/Neur/results/ntk_scaled_rope/seed_999.json\n",
      "- /content/Neur/results/rope/seed_123.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: PHASE 6 — Artifact check\n",
    "from pathlib import Path\n",
    "\n",
    "must_exist = [\n",
    "    ROOT / 'results' / 'summary.csv',\n",
    "    ROOT / 'results' / 'summary.tex',\n",
    "    ROOT / 'figures' / 'ppl_vs_length.pdf',\n",
    "    ROOT / 'figures' / 'ppl_vs_length_with_errorbars.pdf',\n",
    "    ROOT / 'figures' / 'spectral_profile.pdf',\n",
    "    ROOT / 'figures' / 'effective_period.pdf',\n",
    "]\n",
    "\n",
    "for p in must_exist:\n",
    "    print(('OK  ' if p.exists() else 'MISS'), p)\n",
    "\n",
    "print('\\nSample result files:')\n",
    "for p in sorted((ROOT / 'results').rglob('*.json'))[:12]:\n",
    "    print('-', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
